{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" id=\"top\">\n",
    "<img src=\"https://socialify.git.ci/julep-ai/julep/image?description=1&descriptionEditable=Serverless%20AI%20Workflows%20for%20Data%20%26%20ML%20Teams&font=Source%20Code%20Pro&logo=https%3A%2F%2Fraw.githubusercontent.com%2Fjulep-ai%2Fjulep%2Fdev%2F.github%2Fjulep-logo.svg&owner=1&forks=1&pattern=Solid&stargazers=1&theme=Auto\" alt=\"julep\" />\n",
    "\n",
    "<br>\n",
    "  <p>\n",
    "    <a href=\"https://dashboard.julep.ai\">\n",
    "      <img src=\"https://img.shields.io/badge/Get_API_Key-FF5733?style=logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0id2hpdGUiPjxwYXRoIGQ9Ik0xMiAxTDMgNXYxNGw5IDQgOS00VjVsLTktNHptMCAyLjh2MTYuNEw1IDE2LjJWNi44bDctMy4yem0yIDguMmwtMi0yLTIgMiAyIDIgMi0yeiIvPjwvc3ZnPg==\" alt=\"Get API Key\" height=\"28\">\n",
    "    </a>\n",
    "    <span>&nbsp;</span>\n",
    "    <a href=\"https://docs.julep.ai\">\n",
    "      <img src=\"https://img.shields.io/badge/Documentation-4B32C3?style=logo=gitbook&logoColor=white\" alt=\"Documentation\" height=\"28\">\n",
    "    </a>\n",
    "  </p>\n",
    "  <p>\n",
    "   <a href=\"https://www.npmjs.com/package/@julep/sdk\"><img src=\"https://img.shields.io/npm/v/%40julep%2Fsdk?style=social&amp;logo=npm&amp;link=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2F%40julep%2Fsdk\" alt=\"NPM Version\" height=\"28\"></a>\n",
    "    <span>&nbsp;</span>\n",
    "    <a href=\"https://pypi.org/project/julep\"><img src=\"https://img.shields.io/pypi/v/julep?style=social&amp;logo=python&amp;label=PyPI&amp;link=https%3A%2F%2Fpypi.org%2Fproject%2Fjulep\" alt=\"PyPI - Version\" height=\"28\"></a>\n",
    "    <span>&nbsp;</span>\n",
    "    <a href=\"https://hub.docker.com/u/julepai\"><img src=\"https://img.shields.io/docker/v/julepai/agents-api?sort=semver&amp;style=social&amp;logo=docker&amp;link=https%3A%2F%2Fhub.docker.com%2Fu%2Fjulepai\" alt=\"Docker Image Version\" height=\"28\"></a>\n",
    "    <span>&nbsp;</span>\n",
    "    <a href=\"https://choosealicense.com/licenses/apache/\"><img src=\"https://img.shields.io/github/license/julep-ai/julep\" alt=\"GitHub License\" height=\"28\"></a>\n",
    "  </p>\n",
    "  \n",
    "  <h3>\n",
    "    <a href=\"https://discord.com/invite/JTSBGRZrzj\" rel=\"dofollow\">Discord</a>\n",
    "    ¬∑\n",
    "    <a href=\"https://x.com/julep_ai\" rel=\"dofollow\">ùïè</a>\n",
    "    ¬∑\n",
    "    <a href=\"https://www.linkedin.com/company/julep-ai\" rel=\"dofollow\">LinkedIn</a>\n",
    "  </h3>\n",
    "</div>\n",
    "\n",
    "# Hacker News Personalized Newsletter Generator\n",
    "\n",
    "## Overview\n",
    "\n",
    "This cookbook demonstrates how to build an intelligent newsletter generator that fetches top stories from Hacker News, personalizes content based on user preferences, and creates curated summaries. The agent analyzes story relevance using AI, scrapes full article content, and generates insightful summaries for a truly personalized reading experience.\n",
    "\n",
    "## What This Cookbook Does\n",
    "\n",
    "The Hacker News agent performs the following workflow:\n",
    "\n",
    "1. **Fetches Top Stories**: Retrieves the latest top stories from Hacker News API\n",
    "2. **Filters by Score**: Only includes stories that meet a minimum score threshold\n",
    "3. **Scrapes Article Content**: Uses Spider web scraping to get full article content in markdown format\n",
    "4. **Fetches Comments**: Retrieves top comments for each story to provide community context\n",
    "5. **Personalizes Content**: Scores each story based on user's technology interests (0-100)\n",
    "6. **Generates Summaries**: Creates concise, insightful summaries for relevant stories\n",
    "7. **Formats Output**: Produces a clean newsletter format with titles, URLs, and summaries\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Parallel Processing**: Fetches story details, article content, and comments in parallel for efficiency\n",
    "- **Smart Filtering**: Two-stage filtering - first by HN score, then by personalization relevance\n",
    "- **Full Content Analysis**: Goes beyond titles to analyze actual article content\n",
    "- **Community Context**: Includes top comments to capture community insights\n",
    "- **Customizable Parameters**: Configurable minimum score, number of stories, and user interests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install julep -U --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "AGENT_UUID = uuid.uuid4()\n",
    "TASK_UUID = uuid.uuid4() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Julep Client with the API Key\n",
    "\n",
    "Get your API key from [here](https://dashboard.julep.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julep import Client\n",
    "import os\n",
    "\n",
    "JULEP_API_KEY = \"your-api-key\"\n",
    "\n",
    "# Create a Julep client\n",
    "client = Client(api_key=JULEP_API_KEY, environment=\"production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an \"agent\"\n",
    "\n",
    "Agent is the object to which LLM settings, like model, temperature along with tools are scoped to.\n",
    "\n",
    "To learn more about the agent, please refer to the Agent section in [Julep Concepts](https://docs.julep.ai/docs/concepts/agents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the agent\n",
    "name = \"Hacker News Agent\"\n",
    "about = \"A hacker news agent that can fetch the top stories from Hacker News and summarize them.\"\n",
    "\n",
    "# Create the agent\n",
    "agent = client.agents.create_or_update(\n",
    "    agent_id=AGENT_UUID,\n",
    "    name=name,\n",
    "    about=about,\n",
    "    model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Task\n",
    "\n",
    "Tasks in Julep are Github-Actions-style workflows that define long-running, multi-step actions.\n",
    "\n",
    "You can use them to conduct complex actions by defining them step-by-step.\n",
    "\n",
    "To learn more about tasks, please refer to the `Tasks` section in [Julep Concepts](https://docs.julep.ai/docs/concepts/tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "SPIDER_API_KEY = \"spider-api-key\"\n",
    "\n",
    "# Defining the task\n",
    "task_def = yaml.safe_load(f\"\"\"\n",
    "name: HN Newsletter Generator\n",
    "description: Fetch top Hacker News stories, personalize content\n",
    "input_schema:\n",
    "type: object\n",
    "properties:\n",
    "    min_score:\n",
    "    type: integer\n",
    "    default: 50\n",
    "    num_stories:\n",
    "    type: integer\n",
    "    default: 10\n",
    "    description: Number of stories to include in newsletter\n",
    "    user_preferences:\n",
    "    type: array\n",
    "    items:\n",
    "        type: string\n",
    "    description: User's technology interests (e.g., [\"AI/ML\", \"Python\", \"Startups\"])\n",
    "\n",
    "tools:\n",
    "# Fetch top story IDs from Hacker News\n",
    "- name: fetch_hn_stories\n",
    "type: api_call\n",
    "api_call:\n",
    "    method: GET\n",
    "    url: https://hacker-news.firebaseio.com/v0/topstories.json\n",
    "    headers:\n",
    "    Content-Type: application/json\n",
    "\n",
    "# Get detailed information for a specific story\n",
    "- name: get_story_details\n",
    "type: api_call\n",
    "api_call:\n",
    "    method: GET\n",
    "    url: \"https://example.com\"\n",
    "    headers:\n",
    "    Content-Type: application/json\n",
    "\n",
    "# Fetch individual comment details\n",
    "- name: get_comment_details\n",
    "type: api_call\n",
    "api_call:\n",
    "    method: GET\n",
    "    url: https://hacker-news.firebaseio.com/v0/item/{{comment_id}}.json\n",
    "\n",
    "# Spider web scraping integration\n",
    "- name: spider_fetch\n",
    "type: integration\n",
    "integration:\n",
    "    provider: spider\n",
    "    setup:\n",
    "    spider_api_key: {SPIDER_API_KEY}\n",
    "\n",
    "main:\n",
    "# Step 0: Fetch top story IDs from Hacker News\n",
    "# This returns an array of story IDs sorted by ranking (typically returns 500 IDs)\n",
    "- tool: fetch_hn_stories\n",
    "arguments:\n",
    "    url: \"https://hacker-news.firebaseio.com/v0/topstories.json\"\n",
    "label: fetch_story_ids\n",
    "\n",
    "# Step 1: Extract first 50 story IDs\n",
    "# We limit to 50 to avoid overwhelming API calls while still having enough stories to filter\n",
    "- evaluate:\n",
    "    story_ids: $ steps[\"fetch_story_ids\"].output.json[:50]\n",
    "    message: $ f\"Fetched {{len(steps['fetch_story_ids'].output.json)}} stories, processing top 50\"\n",
    "label: extract_ids\n",
    "\n",
    "# Step 2: Fetch details for each story in parallel\n",
    "# Retrieves full story data (title, url, score, comments count) for each ID with parallelism of 10\n",
    "- over: $ steps[\"extract_ids\"].output[\"story_ids\"]\n",
    "parallelism: 10\n",
    "map:\n",
    "    tool: get_story_details\n",
    "    arguments:\n",
    "    method: GET\n",
    "    url: $ f\"https://hacker-news.firebaseio.com/v0/item/{{_}}.json\"\n",
    "label: all_stories\n",
    "\n",
    "# Step 3: Extract successfully fetched story data from the API responses\n",
    "- evaluate:\n",
    "    stories: $ [item[\"json\"] for item in _ if item and \"json\" in item]\n",
    "label: extract_stories\n",
    "\n",
    "# Step 4: Filter by score\n",
    "# Only keep stories that meet the minimum score threshold (default: 50 points)\n",
    "- evaluate:\n",
    "    filtered: $ [s for s in steps[\"extract_stories\"][\"output\"][\"stories\"] if \"score\" in s and s[\"score\"] >= inputs.get(\"min_score\", 50)]\n",
    "label: filter_stories\n",
    "\n",
    "# Step 5: Sort stories by score and limit to requested number\n",
    "# Takes top N stories based on num_stories input parameter (default: 10)\n",
    "- evaluate:\n",
    "    sorted_stories: '$ steps[\"filter_stories\"][\"output\"][\"filtered\"][:inputs.get(\"num_stories\", 10)]'\n",
    "label: sort_stories\n",
    "\n",
    "# Step 6: Fetch full article content for each story using Spider web scraping\n",
    "# Spider converts web pages to clean markdown format for easier processing\n",
    "- over: $ steps[\"sort_stories\"][\"output\"][\"sorted_stories\"]\n",
    "parallelism: 4\n",
    "map:\n",
    "    tool: spider_fetch\n",
    "    arguments:\n",
    "    url: $ _['url']\n",
    "    params:\n",
    "        request: smart_mode\n",
    "        return_format: markdown\n",
    "        proxy_enabled: $ True\n",
    "        filter_output_images: $ True\n",
    "        filter_output_svg: $ True\n",
    "        readability: $ True\n",
    "        limit: 1\n",
    "label: fetch_content\n",
    "\n",
    "# Step 7: Extract scraped content from Spider responses\n",
    "# Handles cases where scraping might fail for some URLs\n",
    "- evaluate:\n",
    "    scraped_contents: '$ [item[\"result\"][0][\"content\"] if item and \"result\" in item and item[\"result\"] and \"content\" in item[\"result\"][0] else \"\" for item in _]'\n",
    "label: extract_scraped_content\n",
    "\n",
    "# Step 8: Prepare comment fetching by creating pairs of story ID and comment ID\n",
    "# Gets up to 3 top comments per story for context\n",
    "- evaluate:\n",
    "    comment_pairs: '$ [{{\"story_id\": story[\"id\"], \"story_index\": idx, \"comment_id\": kid}} for idx, story in \n",
    "enumerate(steps[\"sort_stories\"][\"output\"][\"sorted_stories\"]) if \"kids\" in story for kid in story[\"kids\"][:3]]'\n",
    "label: prepare_comments\n",
    "\n",
    "# Step 9: Fetch all comment details in parallel\n",
    "# Higher parallelism (15) since comments are smaller and faster to fetch\n",
    "- over: '$ steps[\"prepare_comments\"][\"output\"][\"comment_pairs\"]'\n",
    "parallelism: 15\n",
    "map:\n",
    "    tool: get_comment_details\n",
    "    arguments:\n",
    "    method: GET\n",
    "    url: '$ f\"https://hacker-news.firebaseio.com/v0/item/{{_[\\\"comment_id\\\"]}}.json\"'\n",
    "label: fetch_all_comments\n",
    "\n",
    "# Step 10: Extract just the comment data\n",
    "# Filters out any failed comment fetches\n",
    "- evaluate:\n",
    "    comment_results: '$ [item[\"json\"] for item in _ if item and \"json\" in item and item[\"json\"]]'\n",
    "label: extract_comments\n",
    "\n",
    "# Step 11: Group comments by their parent story index\n",
    "# This maintains the relationship between comments and their stories\n",
    "- evaluate:\n",
    "    comments_grouped: '$ [[pair[\"story_index\"], steps[\"extract_comments\"][\"output\"][\"comment_results\"][i]] for i, pair in \n",
    "enumerate(steps[\"prepare_comments\"][\"output\"][\"comment_pairs\"])]'\n",
    "label: comments_with_index\n",
    "\n",
    "# Step 12: Combine stories with their scraped content and top comments\n",
    "# Creates a complete data structure for each story\n",
    "- evaluate:\n",
    "    stories_with_comments: '$ [dict(story, content=steps[\"extract_scraped_content\"][\"output\"][\"scraped_contents\"][i], top_comments=[item[1] for item in \n",
    "steps[\"comments_with_index\"][\"output\"][\"comments_grouped\"] if item[0] == i]) for i, story in enumerate(steps[\"sort_stories\"][\"output\"][\"sorted_stories\"])]'\n",
    "label: final_stories_with_comments\n",
    "\n",
    "# Step 13: Score each story individually based on user preferences\n",
    "# Uses LLM to analyze relevance to user's specified interests\n",
    "# Returns a score 0-100 for personalization\n",
    "- over: $ steps[\"final_stories_with_comments\"][\"output\"][\"stories_with_comments\"]\n",
    "parallelism: 10\n",
    "map:\n",
    "    prompt:\n",
    "    - role: system\n",
    "        content: |-\n",
    "        $ f'''\n",
    "        You are a content curator. Score this HN story's relevance to the user's interests.\n",
    "        User interests: $ {{ steps[0].input.user_preferences }}\n",
    "\n",
    "        Return only a JSON object with the relevance score (0-100).\n",
    "        Return ONLY raw JSON without markdown code blocks\n",
    "        '''\n",
    "    - role: user\n",
    "        content: >-\n",
    "        $ f'''\n",
    "        Story to analyze:\n",
    "        Title: $ {{ _[\"title\"] }}\n",
    "        URL: $ {{ _[\"url\"] }}\n",
    "        Score: $ {{ _[\"score\"] }}\n",
    "        Content preview: $ {{ _[\"content\"]}}\n",
    "        Top comment: $ {{ _[\"top_comments\"][0][\"text\"] }}\n",
    "\n",
    "        Return format: \"relevance_score\" from 0 to 100\n",
    "        Return only a JSON object with the relevance score (0-100).\n",
    "        Return ONLY raw JSON without markdown code blocks\n",
    "        '''\n",
    "    unwrap: true\n",
    "label: score_stories\n",
    "\n",
    "# Step 14: Combine original stories with their relevance scores\n",
    "# Creates tuples of story data and personalization score\n",
    "- evaluate:\n",
    "    scored_stories: '$ [{{\"story\": steps[\"final_stories_with_comments\"][\"output\"][\"stories_with_comments\"][i], \"relevance_score\": json.loads(steps[\"score_stories\"][\"output\"][i])[\"relevance_score\"]}} for i in range(len(steps[\"score_stories\"][\"output\"]))]'\n",
    "label: combine_scores\n",
    "\n",
    "# Step 15: Filter stories with relevance >= 60\n",
    "# Only keep stories that are highly relevant to user's interests\n",
    "- evaluate:\n",
    "    personalized_stories: $ [item for item in steps[\"combine_scores\"][\"output\"][\"scored_stories\"] if item[\"relevance_score\"] >= 60]\n",
    "label: filter_personalized\n",
    "\n",
    "# Step 16: Generate concise summaries for each personalized story\n",
    "# Creates 100-word summaries highlighting key insights\n",
    "- over: $ steps[\"filter_personalized\"][\"output\"][\"personalized_stories\"]\n",
    "parallelism: 10\n",
    "map:\n",
    "    prompt:\n",
    "    - role: system\n",
    "        content: |\n",
    "        Generate a concise, insightful summary (max 100 words) for this article.\n",
    "        Focus on key insights and why it matters.\n",
    "    - role: user\n",
    "        content: >-\n",
    "        $ f'''\n",
    "        Title: {{ _[\"story\"][\"title\"] }}\n",
    "        Content: {{ _[\"story\"][\"content\"] }}\n",
    "        Top comments: {{ _[\"story\"][\"top_comments\"] }}\n",
    "        '''\n",
    "    unwrap: true\n",
    "label: generate_summaries\n",
    "\n",
    "# Step 17: Prepare final output structure\n",
    "# Formats all data into a clean structure\n",
    "# Includes title, URLs, comment count, and generated summary\n",
    "- evaluate:\n",
    "    final_output: |\n",
    "    $ [{{\n",
    "        \"title\": steps[\"filter_personalized\"][\"output\"][\"personalized_stories\"][i][\"story\"][\"title\"],\n",
    "        \"url\": steps[\"filter_personalized\"][\"output\"][\"personalized_stories\"][i][\"story\"][\"url\"],\n",
    "        \"hn_url\": f\"https://news.ycombinator.com/item?id={{steps['filter_personalized']['output']['personalized_stories'][i]['story']['id']}}\",\n",
    "        \"comments_count\": steps[\"filter_personalized\"][\"output\"][\"personalized_stories\"][i][\"story\"].get(\"descendants\", 0),\n",
    "        \"summary\": steps[\"generate_summaries\"][\"output\"][i]\n",
    "    }} for i in range(len(steps[\"filter_personalized\"][\"output\"][\"personalized_stories\"]))]\n",
    "label: prepare_final_output\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = client.tasks.create_or_update(\n",
    "    task_id=TASK_UUID,\n",
    "    agent_id=AGENT_UUID,\n",
    "    **task_def\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Execution\n",
    "\n",
    "An execution is a single run of a task. It is a way to run a task with a specific set of inputs.\n",
    "\n",
    "To learn more about executions, please refer to the `Executions` section in [Julep Concepts](https://docs.julep.ai/docs/concepts/execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = client.executions.create(\n",
    "    task_id=task.id,\n",
    "    input={\n",
    "        \"min_score\": 50,\n",
    "        \"num_stories\": 10,\n",
    "        \"user_preferences\": [\"AI/ML\", \"Python\", \"Startups\", \"tech\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Transitions\n",
    "\n",
    "This method lists all the task steps that have been executed up to this point in time, so the output of a successful execution will be the output of the last transition (first in the transition list as it is in reverse chronological order), which should have a type of `finish`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = []\n",
    "of = 0\n",
    "\n",
    "while new_transitions:= client.executions.transitions.list(execution.id, limit=100, offset=of).items:\n",
    "    transitions.extend(new_transitions)\n",
    "    of += 100\n",
    "\n",
    "for i, transition in enumerate(transitions):\n",
    "    print(f\"Transition index: {len(transitions) - i}, type: {transition.type}, current: {transition.current}, next: {transition.next}\")\n",
    "    print(\"-\" * 10)\n",
    "    print(transition.output)\n",
    "    print(\"/\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = client.executions.get(execution.id)\n",
    "\n",
    "print(execution.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
