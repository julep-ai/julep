{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the Julep Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade julep --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# NOTE: these UUIDs are used in order not to use the `create_or_update` methods instead of\n",
    "# the `create` methods for the sake of not creating new resources every time a cell is run.\n",
    "AGENT_UUID = uuid.uuid4()\n",
    "TASK_UUID = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating julep client with the api key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julep import Client\n",
    "import os\n",
    "\n",
    "JULEP_API_KEY = os.environ.get(\"JULEP_API_KEY\")\n",
    "\n",
    "# Create a Julep client\n",
    "client = Client(api_key=JULEP_API_KEY, environment=\"production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an \"agent\"\n",
    "\n",
    "Agent is the object to which LLM settings, like model, temperature along with tools are scoped to.\n",
    "\n",
    "To learn more about the agent, please refer to the Agent section in [Julep Concepts](https://docs.julep.ai/docs/concepts/agents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "agent = client.agents.create_or_update(\n",
    "    agent_id=AGENT_UUID,\n",
    "    name=\"Spiderman\",\n",
    "    about=\"AI that can crawl the web and extract data\",\n",
    "    model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Task\n",
    "\n",
    "Tasks in Julep are Github-Actions-style workflows that define long-running, multi-step actions.\n",
    "\n",
    "You can use them to conduct complex actions by defining them step-by-step.\n",
    "\n",
    "To learn more about tasks, please refer to the `Tasks` section in [Julep Concepts](https://docs.julep.ai/docs/concepts/tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "cloudinary_api_key = os.environ[\"CLOUDINARY_API_KEY\"]\n",
    "cloudinary_api_secret = os.environ[\"CLOUDINARY_API_SECRET\"]\n",
    "cloudinary_cloud_name = os.environ[\"CLOUDINARY_CLOUD_NAME\"]\n",
    "\n",
    "# Define the task\n",
    "task_def = yaml.safe_load(f\"\"\"\n",
    "# yaml-language-server: $schema=https://raw.githubusercontent.com/julep-ai/julep/refs/heads/dev/src/schemas/create_task_request.json\n",
    "name: Julep Video Processing With Natural Language\n",
    "description: Process a video using natural language instructions\n",
    "\n",
    "########################################################\n",
    "####################### INPUT SCHEMA ###################\n",
    "########################################################\n",
    "input_schema:\n",
    "  type: object\n",
    "  properties:\n",
    "    video_url:\n",
    "      type: string\n",
    "      description: The url of the file to upload\n",
    "    public_id:\n",
    "      type: string\n",
    "      description: The public id of the file to upload\n",
    "    transformation_prompt:\n",
    "      type: string\n",
    "      description: The prompt for the transformations to apply to the file\n",
    "\n",
    "########################################################\n",
    "####################### TOOLS ##########################\n",
    "########################################################\n",
    "                          \n",
    "# Define the tools that the task will use in this workflow\n",
    "tools:\n",
    "- name: cloudinary_upload\n",
    "  type: integration\n",
    "  integration:\n",
    "    provider: cloudinary\n",
    "    method: media_upload\n",
    "    setup:\n",
    "      cloudinary_api_key: \"{cloudinary_api_key}\"\n",
    "      cloudinary_api_secret: \"{cloudinary_api_secret}\"\n",
    "      cloudinary_cloud_name: \"{cloudinary_cloud_name}\"\n",
    "\n",
    "########################################################\n",
    "####################### MAIN WORKFLOW ##################\n",
    "########################################################\n",
    "\n",
    "main:\n",
    "# Step 0: Upload the video to cloudinary\n",
    "- tool: cloudinary_upload\n",
    "  arguments:\n",
    "    file: $ steps[0].input.video_url\n",
    "    public_id: $ steps[0].input.public_id\n",
    "    upload_params:\n",
    "      resource_type: video\n",
    "\n",
    "# Step 1: Generate the transformation json\n",
    "- prompt:\n",
    "  - role: user\n",
    "    content:\n",
    "\n",
    "      - type: text\n",
    "        text: |-\n",
    "          You are a Cloudinary expert. You are given a medial url. it might be an image or a video.\n",
    "          You need to come up with a json of transformations to apply to the given media.\n",
    "          Overall the json could have multiple transformation json objects.\n",
    "          Each transformation json object can have the multiple key value pairs.\n",
    "          Each key value pair should have the key as the transformation name like \"aspect_ratio\", \"crop\", \"width\" etc and the value as the transformation parameter value.\n",
    "          Note: Provide the image url as it is when overlaying images.\n",
    "          Note: When you use overlay with an image url, you need to add a nested json containing url: <image_url>\n",
    "          Given below is an example of some key value pairs that you might need to use when constructing the json.\n",
    "            \"aspect_ratio\": \"1.0\",\n",
    "              \"width\": \"250\",\n",
    "              \"fetch_format\": \"auto\"\n",
    "              \"overlay\":\n",
    "                \"url\": \"<image_url>\"\n",
    "              \"flags\": \"layer_apply\"\n",
    "            \n",
    "         \n",
    "      - type: image_url\n",
    "        image_url:\n",
    "          url: $ _.url\n",
    "\n",
    "      - type: text\n",
    "        text: |-\n",
    "          $ f'''Hey, check the video above, I need to apply the following transformations using cloudinary.\n",
    "          {{steps[0].input.transformation_prompt}}'''\n",
    "\n",
    "  unwrap: true\n",
    "  settings:\n",
    "    model: gemini/gemini-1.5-pro\n",
    "\n",
    "# Step 2: Extract the json from the model's response\n",
    "- evaluate:\n",
    "    model_transformation: >-\n",
    "      $ extract_json(_)\n",
    "\n",
    "# Step 3: Upload the video to cloudinary\n",
    "- tool: cloudinary_upload\n",
    "  arguments:\n",
    "    file: $ steps[0].input.video_url\n",
    "    public_id: $ steps[0].input.public_id\n",
    "    upload_params:\n",
    "      transformation: $ _.model_transformation\n",
    "      resource_type: video\n",
    "\n",
    "# Step 4: Return the transformed video url\n",
    "- evaluate:\n",
    "    transformed_video_url: $ _.url\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the task object\n",
    "task = client.tasks.create_or_update(\n",
    "    task_id=TASK_UUID,\n",
    "    agent_id=AGENT_UUID,\n",
    "    **task_def\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Execution\n",
    "\n",
    "An execution is a single run of a task. It is a way to run a task with a specific set of inputs.\n",
    "\n",
    "To learn more about executions, please refer to the `Executions` section in [Julep Concepts](https://docs.julep.ai/docs/concepts/execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'067ffb5c-1240-7967-8000-a40019c3084d'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an execution object\n",
    "transformation_prompt = \"\"\"\n",
    "1- I want to add an overlay an the following image to the video, and apply a layer apply flag also. Here's the image url:\n",
    "https://avatars.githubusercontent.com/u/112750682?s=200&v=4\n",
    "\n",
    "2- I also want you to to blur the video, and add a fade in and fade out effect to the video with a duration of 3 seconds each.\n",
    "\"\"\"\n",
    "\n",
    "input_video_url = \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4\"\n",
    "\n",
    "execution = client.executions.create(\n",
    "    task_id=TASK_UUID,\n",
    "    input={\n",
    "        \"video_url\":  input_video_url,\n",
    "        \"public_id\": \"video_test2\",\n",
    "        \"transformation_prompt\": transformation_prompt,\n",
    "    }\n",
    ")\n",
    "execution.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking execution details and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to get the execution details and the output:\n",
    "\n",
    "1. **Get Execution Details**: This method retrieves the details of the execution, including the output of the last transition that took place.\n",
    "\n",
    "2. **List Transitions**: This method lists all the task steps that have been executed up to this point in time, so the output of a successful execution will be the output of the last transition (first in the transition list as it is in reverse chronological order), which should have a type of `finish`.\n",
    "\n",
    "\n",
    "<span style=\"color:olive;\">Note: You need to wait for a few seconds for the execution to complete before you can get the final output, so feel free to run the following cells multiple times until you get the final output.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://res.cloudinary.com/dpnjjk8mb/video/upload/v1738934100/video_test2.mp4', 'base64': None, 'meta_data': {'url': 'http://res.cloudinary.com/dpnjjk8mb/video/upload/v1738934100/video_test2.mp4', 'tags': [], 'type': 'upload', 'audio': {'codec': 'aac', 'bit_rate': '191999', 'channels': 2, 'frequency': 44100, 'channel_layout': 'stereo'}, 'bytes': 2252313, 'video': {'codec': 'h264', 'level': 31, 'profile': 'High', 'bit_rate': '1002377', 'time_base': '1/48', 'pix_format': 'yuv420p'}, 'width': 1280, 'format': 'mp4', 'height': 720, 'api_key': '518455844981529', 'version': 1738934100, 'asset_id': '069d70c84e88ee9293a1d753b3ca3898', 'bit_rate': 1197518, 'duration': 15.046531, 'existing': True, 'is_audio': False, 'rotation': 0, 'nb_frames': 361, 'signature': '836eddb515d796dc8484d7dc108cb67fbe0ba1d5', 'created_at': '2024-11-20T08:55:44Z', 'frame_rate': 24.0, 'version_id': '85846ee1c860645e1149e8029051c07d', 'placeholder': False, 'asset_folder': '', 'display_name': 'video_test2', 'playback_url': 'https://res.cloudinary.com/dpnjjk8mb/video/upload/sp_auto/v1738934100/video_test2.m3u8', 'resource_type': 'video'}, 'public_id': 'video_test2'}\n"
     ]
    }
   ],
   "source": [
    "# Get execution details\n",
    "execution = client.executions.get(execution.id)\n",
    "# Print the output\n",
    "print(execution.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition type:  init\n",
      "Transition output:  {'public_id': 'video_test2', 'video_url': 'http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4', 'transformation_prompt': \"\\n1- I want to add an overlay an the following image to the video, and apply a layer apply flag also. Here's the image url:\\nhttps://avatars.githubusercontent.com/u/112750682?s=200&v=4\\n\\n2- I also want you to to blur the video, and add a fade in and fade out effect to the video with a duration of 3 seconds each.\\n\"}\n",
      "--------------------------------------------------\n",
      "Transition type:  step\n",
      "Transition output:  {'url': 'https://res.cloudinary.com/dpnjjk8mb/video/upload/v1738934100/video_test2.mp4', 'base64': None, 'meta_data': {'url': 'http://res.cloudinary.com/dpnjjk8mb/video/upload/v1738934100/video_test2.mp4', 'tags': [], 'type': 'upload', 'audio': {'codec': 'aac', 'bit_rate': '191999', 'channels': 2, 'frequency': 44100, 'channel_layout': 'stereo'}, 'bytes': 2252313, 'video': {'codec': 'h264', 'level': 31, 'profile': 'High', 'bit_rate': '1002377', 'time_base': '1/48', 'pix_format': 'yuv420p'}, 'width': 1280, 'format': 'mp4', 'height': 720, 'api_key': '518455844981529', 'version': 1738934100, 'asset_id': '069d70c84e88ee9293a1d753b3ca3898', 'bit_rate': 1197518, 'duration': 15.046531, 'existing': True, 'is_audio': False, 'rotation': 0, 'nb_frames': 361, 'signature': '836eddb515d796dc8484d7dc108cb67fbe0ba1d5', 'created_at': '2024-11-20T08:55:44Z', 'frame_rate': 24.0, 'version_id': '85846ee1c860645e1149e8029051c07d', 'placeholder': False, 'asset_folder': '', 'display_name': 'video_test2', 'playback_url': 'https://res.cloudinary.com/dpnjjk8mb/video/upload/sp_auto/v1738934100/video_test2.m3u8', 'resource_type': 'video'}, 'public_id': 'video_test2'}\n",
      "--------------------------------------------------\n",
      "Transition type:  step\n",
      "Transition output:  Sure, here's the JSON representation of the Cloudinary transformations you requested to apply to your video:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"overlay\": {\n",
      "      \"url\": \"https://avatars.githubusercontent.com/u/112750682?s=200&v=4\"\n",
      "    },\n",
      "    \"flags\": \"layer_apply\"\n",
      "  },\n",
      "  {\n",
      "    \"effect\": \"blur:100\" \n",
      "  },\n",
      "  {\n",
      "    \"effect\": \"fade:3000\"\n",
      "  },\n",
      "   {\n",
      "     \"effect\": \"fade:-3000\"\n",
      "   }\n",
      "]\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **Overlay:** The `overlay` parameter specifies the image to be overlaid on the video. The nested `url` object provides the URL of the overlay image. The `flags: \"layer_apply\"` ensures that the transformations are applied to the overlay image and not to the base video.\n",
      "\n",
      "* **Blur:**  The `effect: \"blur:100\"` applies a blur effect to the video. The value `100` represents the blur strength. You can adjust this value to control the intensity of the blur.\n",
      "\n",
      "* **Fade In and Fade Out:** The `effect: \"fade:3000\"` and the `effect: \"fade:-3000\"` applies the fade-in and fade-out effects to the video for the start and ending respectively, both having a duration of 3 seconds (3000 milliseconds).\n",
      "\n",
      "\n",
      "You can apply these transformations by including them in the delivery URL of your video in Cloudinary's Dynamic Image Manipulation syntax.  The order of transformations in the JSON array matters; they are applied sequentially. If the transformation is not being applied check whether you have provided a video url or an image url to Cloudinary and modify the transformation array if needed.\n",
      "--------------------------------------------------\n",
      "Transition type:  step\n",
      "Transition output:  {'model_transformation': [{'flags': 'layer_apply', 'overlay': {'url': 'https://avatars.githubusercontent.com/u/112750682?s=200&v=4'}}, {'effect': 'blur:100'}, {'effect': 'fade:3000'}, {'effect': 'fade:-3000'}]}\n",
      "--------------------------------------------------\n",
      "Transition type:  step\n",
      "Transition output:  {'url': 'https://res.cloudinary.com/dpnjjk8mb/video/upload/v1744811467/video_test2.mp4', 'base64': None, 'meta_data': {'url': 'http://res.cloudinary.com/dpnjjk8mb/video/upload/v1744811467/video_test2.mp4', 'etag': 'a4dccd7720185599448773735e49ad8a', 'tags': [], 'type': 'upload', 'audio': {'codec': 'aac', 'bit_rate': '128290', 'channels': 2, 'frequency': 44100, 'channel_layout': 'stereo'}, 'bytes': 1100622, 'pages': 0, 'video': {'codec': 'h264', 'level': 31, 'profile': 'High', 'bit_rate': '450256', 'time_base': '1/12288', 'pix_format': 'yuv420p'}, 'width': 1280, 'format': 'mp4', 'height': 720, 'api_key': '518455844981529', 'version': 1744811467, 'asset_id': '069d70c84e88ee9293a1d753b3ca3898', 'bit_rate': 585203, 'duration': 15.046009, 'is_audio': False, 'rotation': 0, 'nb_frames': 361, 'signature': '0f965ee84e69beacefff7b9e285bb621884109af', 'created_at': '2024-11-20T08:55:44Z', 'frame_rate': 24.0, 'version_id': '637b3869e172dad6380706279cb32f02', 'overwritten': True, 'placeholder': False, 'asset_folder': '', 'display_name': 'video_test2', 'playback_url': 'https://res.cloudinary.com/dpnjjk8mb/video/upload/sp_auto/v1744811467/video_test2.m3u8', 'resource_type': 'video', 'original_filename': 'ForBiggerMeltdowns'}, 'public_id': 'video_test2'}\n",
      "--------------------------------------------------\n",
      "Transition type:  finish\n",
      "Transition output:  {'transformed_video_url': 'https://res.cloudinary.com/dpnjjk8mb/video/upload/v1744811467/video_test2.mp4'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists all the task steps that have been executed up to this point in time\n",
    "transitions = client.executions.transitions.list(execution_id=execution.id).items\n",
    "\n",
    "# Transitions are retrieved in reverse chronological order\n",
    "for transition in reversed(transitions):\n",
    "    print(\"Transition type: \", transition.type)\n",
    "    print(\"Transition output: \", transition.output)\n",
    "    print(\"-\"*50)\n",
    "\n",
    "if transitions[0].type == \"finish\":\n",
    "    transformed_video_url = transitions[0].output['transformed_video_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Concepts\n",
    "\n",
    "- [Agents](https://docs.julep.ai/concepts/agents)\n",
    "- [Tasks](https://docs.julep.ai/concepts/tasks)\n",
    "- [Tasks](https://docs.julep.ai/concepts/tasks)lep.ai/concepts/tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
