{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://socialify.git.ci/julep-ai/julep/image?description=1&descriptionEditable=Build%20AI%20agents%20and%20workflows%20with%20a%20simple%20API&font=Source%20Code%20Pro&logo=https%3A%2F%2Fraw.githubusercontent.com%2Fjulep-ai%2Fjulep%2Fdev%2F.github%2Fjulep-logo.svg&owner=1&pattern=Solid&stargazers=1&theme=Auto\" alt=\"julep\" width=\"640\" height=\"320\" />\n",
    "</div>\n",
    "\n",
    "## Task Definition: Spider Crawler Integration\n",
    "\n",
    "### Overview\n",
    "\n",
    "This task is a simple task that leverages the spider `integration` tool, and combines it with a prompt step to crawl a website for a given URL, and then create a summary of the results.\n",
    "\n",
    "### Task Tools:\n",
    "\n",
    "**Spider Crawler**: An `integration` type tool that can crawl the web and extract data from a given URL.\n",
    "\n",
    "### Task Input:\n",
    "\n",
    "**url**: The URL of the website to crawl.\n",
    "\n",
    "### Task Output:\n",
    "\n",
    "**output**: A dictionary that contains a `documents` key which contains the extracted data from the given URL. Check the output below for a detailed output schema.\n",
    "\n",
    "### Task Flow\n",
    "\n",
    "1. **Input**: The user provides a URL to crawl.\n",
    "\n",
    "2. **Spider Tool Integration**: The `spider_crawler` tool is called to crawl the web and extract data from the given URL.\n",
    "\n",
    "3. **Prompt Step**: The prompt step is used to create a summary of the results from the spider tool.\n",
    "\n",
    "4. **Output**: The final output is the summary of the results from the spider tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "To recreate the notebook and see the code implementation for this task, you can access the Google Colab notebook using the link below:\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/julep-ai/julep/blob/dev/cookbooks/01-Website_Crawler_using_Spider.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "### Additional Information\n",
    "\n",
    "For more details about the task or if you have any questions, please don't hesitate to contact the author:\n",
    "\n",
    "**Author:** Julep AI  \n",
    "**Contact:** [hey@julep.ai](mailto:hey@julep.ai) or  <a href=\"https://discord.com/invite/JTSBGRZrzj\" rel=\"dofollow\">Discord</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the Julep Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install julep -U --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# NOTE: these UUIDs are used in order not to use the `create_or_update` methods instead of\n",
    "# the `create` methods for the sake of not creating new resources every time a cell is run.\n",
    "AGENT_UUID = uuid.uuid4()\n",
    "TASK_UUID = uuid.uuid4() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Julep Client with the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julep import Client\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"JULEP_API_KEY\")\n",
    "\n",
    "# Create a Julep client\n",
    "client = Client(api_key=api_key, environment=\"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an \"agent\"\n",
    "\n",
    "Agent is the object to which LLM settings, like model, temperature along with tools are scoped to.\n",
    "\n",
    "To learn more about the agent, please refer to the [documentation](https://github.com/julep-ai/julep/blob/dev/docs/julep-concepts.md#agent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "agent = client.agents.create_or_update(\n",
    "    agent_id=AGENT_UUID,\n",
    "    name=\"Spiderman\",\n",
    "    about=\"AI that can crawl the web and extract data\",\n",
    "    model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Task\n",
    "\n",
    "Tasks in Julep are Github-Actions-style workflows that define long-running, multi-step actions.\n",
    "\n",
    "You can use them to conduct complex actions by defining them step-by-step.\n",
    "\n",
    "To learn more about tasks, please refer to the `Tasks` section in [Julep Concepts](https://github.com/julep-ai/julep/blob/dev/docs/julep-concepts.md#tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "spider_api_key = os.getenv(\"SPIDER_API_KEY\")\n",
    "\n",
    "# Define the task\n",
    "task_def = yaml.safe_load(f\"\"\"\n",
    "name: Crawling Task\n",
    "\n",
    "# Define the tools that the agent will use in this workflow\n",
    "tools:\n",
    "- name: spider_crawler\n",
    "  type: integration\n",
    "  integration:\n",
    "    provider: spider\n",
    "    setup:\n",
    "      spider_api_key: \"{spider_api_key}\"\n",
    "\n",
    "# Define the steps of the workflow\n",
    "main:\n",
    "# Define a tool call step that calls the spider_crawler tool with the url input\n",
    "- tool: spider_crawler\n",
    "  arguments:\n",
    "    url: \"_['url']\" # You can also use 'inputs[0]['url']'\n",
    "  \n",
    "    \n",
    "- prompt: |\n",
    "    You are {{{{agent.about}}}}\n",
    "    I have given you this url: {{{{inputs[0]['url']}}}}\n",
    "    And you have crawled that website. Here are the results you found:\n",
    "    {{{{_['documents']}}}}\n",
    "    I want you to create a short summary (no longer than 100 words) of the results you found while crawling that website.\n",
    "\n",
    "  unwrap: True\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow;\">Notes:</span>\n",
    "- The reason for using the quadruple curly braces `{{{{}}}}` for the jinja template is to avoid conflicts with the curly braces when using the `f` formatted strings in python. [More information here](https://stackoverflow.com/questions/64493332/jinja-templating-in-airflow-along-with-formatted-text)\n",
    "- The `unwrap: True` in the prompt step is used to unwrap the output of the prompt step (to unwrap the `choices[0].message.content` from the output of the model).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating/Updating a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the task object\n",
    "task = client.tasks.create_or_update(\n",
    "    task_id=TASK_UUID,\n",
    "    agent_id=AGENT_UUID,\n",
    "    **task_def\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Execution\n",
    "\n",
    "An execution is a single run of a task. It is a way to run a task with a specific set of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a execution worklow for the Task defined in the yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an execution object\n",
    "execution = client.executions.create(\n",
    "    task_id=TASK_UUID,\n",
    "    input={\n",
    "        \"url\": \"https://spider.cloud\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to get the execution details and the output:\n",
    "\n",
    "1. **Get Execution Details**: This method retrieves the details of the execution, including the output of the last transition that took place.\n",
    "\n",
    "2. **List Transitions**: This method lists all the task steps that have been executed up to this point in time, so the output of a successful execution will be the output of the last transition (first in the transition list as it is in reverse chronological order), which should have a type of `finish`.\n",
    "\n",
    "\n",
    "<span style=\"color:yellow;\">Note: You need to wait for a few seconds for the execution to complete before you can get the final output, so feel free to run the following cells multiple times until you get the final output.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider.cloud is a cutting-edge web crawling service designed for AI applications, offering high-speed and cost-effective data collection. Built with a robust Rust engine, Spider supports seamless integration with AI tools and provides various response formats, including LLM-ready markdown. It features concurrent streaming, caching, smart mode with headless Chrome, and auto proxy rotations. Ideal for large-scale projects, Spider ensures compliance with robots.txt and offers a free trial. Trusted by tech leaders, it enables efficient data curation and transformation, with capabilities to handle extreme workloads and dynamic content rendering.\n"
     ]
    }
   ],
   "source": [
    "# Get execution details\n",
    "execution = client.executions.get(execution.id)\n",
    "# Print the output\n",
    "print(execution.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition type:  init\n",
      "Transition output:  {'url': 'https://spider.cloud'}\n",
      "--------------------------------------------------\n",
      "Transition type:  step\n",
      "Transition output:  {'documents': [{'id': None, 'metadata': {'description': 'Experience cutting-edge web crawling with unparalleled speeds, perfect for LLMs, Machine Learning, and Artificial Intelligence. The fastest and most efficient web scraper tailored for AI applications.', 'domain': 'spider.cloud', 'extracted_data': None, 'file_size': 9112, 'keywords': ['AI agent stack', 'AI üï∑Ô∏è Spider', 'AWS infrastructure reduced', 'Auto Proxy rotations', 'Comprehensive Data Curation', 'Concurrent Streaming Save time', 'Data Collecting Projects Today Jumpstart web crawling', 'FAQ Frequently asked questions', 'Fastest Web Crawler', 'Multiple response formats', 'Open Source Spider engine', 'Performance Tuned Spider', 'Seamless Integrations Seamlessly integrate Spider', 'Smart Mode Spider dynamically switches', 'Spider accurately crawls', 'Spider convert web data', 'Spider outputs HTML', 'Toggle Theme Sign InRegister', 'Transform Convert raw HTML', 'WilliamEspegren Web crawler built', 'achieve crawling thousands', 'affordable web scraping', 'and`XML`for API responses', 'caching repeated web page crawls', 'cost step caching', 'crazy resource management Aaaaaaand', 'custom browser scripting', 'data = json', 'data formats including LLM-ready markdown', 'ensure continuous maintenance', 'ensuring data curation perfectly aligned', 'finest data collecting solution', 'full elastic scaling concurrency', 'handle extreme workloads', 'iammerrick Rust based crawler Spider', 'insightful data solutions', 'json headers =', 'large scraping projects', 'large-scale data collection', 'latest AI models', 'leading tech businesses worldwide', 'leading web crawling tool designed', 'real-time web data', 'request Python JSONL Copy ``` import requests', 'requires JavaScript rendering', 'response = requests', 'robust Rust engine scales effortlessly', 'scrapes significantly faster', 'search engine results', 'traditional scraping services Spider API Request Modes', 'training AI models'], 'pathname': '/', 'resource_type': '.md', 'title': 'Spider: The Web Crawler for AI', 'url': '8475428e-4e0c-44de-967f-c14fb73cf490/spider.cloud/_cloud/12638123428881205758.md', 'user_id': '8475428e-4e0c-44de-967f-c14fb73cf490'}, 'page_content': 'Spider: The Web Crawler for AI\\n[Spider](https://spider.cloud/)\\n[Github1k](https://github.com/spider-rs/spider)\\n[API](https://spider.cloud/docs/api)\\n[Docs](https://spider.cloud/docs/overview)\\n[Pricing](https://spider.cloud/credits/new)\\nToggle Theme\\nSign InRegister\\nTo help you get started with Spider, we‚Äôll give you $200 in credits when you spend $100.[Terms apply](https://spider.cloud/promotion-spider-credits)\\n# The Web Crawler for AI Agents and LLMs\\nSpider offers the finest data collecting solution. Engineered for speed and scalability, it allows you to elevate your AI projects.\\n[Get Started](https://spider.cloud/credits/new)View Preview\\n* Basic\\n* Streaming\\nExample request\\nPython\\nJSONL\\nCopy\\n```\\nimport requests, os, json\\nheaders = {\\n \\'Authorization\\': os.getenv(\"SPIDER_API_KEY\"),\\n \\'Content-Type\\': \\'application/jsonl\\',\\n}\\njson_data = {\"limit\":50,\"metadata\":True,\"url\":\"https://spider.cloud\"}\\nresponse = requests.post(\\'https://api.spider.cloud/crawl\\', \\n headers=headers, json=json_data, stream=True)\\nwith response as r:\\n r.raise_for_status()\\nfor chunk in r.iter_lines(\\n chunk_size=None, \\n decode_unicode=True\\n ):\\n data = json.loads(chunk)\\n print(data)\\n```\\n[Free Trial](https://spider.cloud/credits/new?free-trial=1)\\nExample Response\\n## Built with the need for**Speed**\\nExperience the power of**Spider**, built fully in**Rust**for next-generation scalability.\\n### 2.4secs\\nTo crawl over 20,000 pages\\n### 500-1000x\\nFaster than alternatives\\n### 500x\\nCheaper than traditional scraping services\\nSpider API Request Modes ¬∑ Benchmarked tailwindcss.com ¬∑06/16/2024\\n[See framework benchmarks](https://github.com/spider-rs/spider/blob/main/benches/BENCHMARKS.md)\\n### Seamless Integrations\\nSeamlessly integrate Spider with a wide range of platforms, ensuring data curation perfectly aligned with your requirements. Compatible with all major AI tools.\\n[LangChain integration](https://python.langchain.com/docs/integrations/document_loaders/spider)[LlamaIndex integration](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/#using-spider-reader)[CrewAI integration](https://docs.crewai.com/tools/SpiderTool/)[FlowWiseAI integration](https://docs.flowiseai.com/integrations/langchain/document-loaders/spider-web-scraper-crawler)[Composio integration](https://docs.composio.dev/introduction/foundations/components/list_local_tools#spider-crawler)[PhiData integration](https://docs.phidata.com/tools/spider)\\n### Concurrent Streaming\\nSave time and money without having to worry about bandwidth concerns by effectively streaming all the results concurrently. The latency cost that is saved becomes drastic as you crawl more websites.\\n### Warp Speed\\nPowered by the cutting-edge[Spider](https://github.com/spider-rs/spider)open-source project, our robust Rust engine scales effortlessly to handle extreme workloads. We ensure continuous maintenance and improvement for top-tier performance.\\n## Kickstart Your Data Collecting Projects Today\\nJumpstart web crawling with full elastic scaling concurrency, optimal formats, and AI scraping.\\n### Performance Tuned\\nSpider is written in Rust and runs in full concurrency to achieve crawling thousands of pages in secs.\\n### Multiple response formats\\nGet clean and formatted markdown, HTML, or text content for fine-tuning or training AI models.\\n### Caching\\nFurther boost speed by caching repeated web page crawls to minimize expenses while building.\\n### Smart Mode\\nSpider dynamically switches to Headless Chrome when it needs to quick.\\nBeta\\n### Scrape with AI\\nDo custom browser scripting and data extraction using the latest AI models with no cost step caching.\\n### The crawler for LLMs\\nDon\\'t let crawling and scraping be the highest latency in your LLM & AI agent stack.\\n### Scrape with no headaches\\n* Auto Proxy rotations\\n* Agent headers\\n* Anti-bot detections\\n* Headless chrome\\n* Markdown responses\\n### The Fastest Web Crawler\\n* Powered by[spider-rs](https://github.com/spider-rs/spider)\\n* 20,000 pages/seconds\\n* Unlimited concurrency\\n* Simple API\\n* 50,000 RPM\\n### Do more with AI\\n* Browser scripting\\n* Advanced extraction\\n* Data pipelines\\n* Ideal for LLMs and AI Agents\\n* Accurate labeling\\n## Achieve more with these new API features\\nOur API is set to stream so you can act in realtime.\\n### Search\\nGet access to search engine results from anywhere and easily crawl and transform pages to LLM-ready markdown.\\n[Explore Search](https://spider.cloud/docs/api#search)\\n### Transform\\nConvert raw HTML into markdown easily by using this API. Transform thousands of html pages in seconds.\\n[Explore Transform](https://spider.cloud/docs/api#transform)\\n## Join the community\\nBacked by a network of early advocates, contributors, and supporters.\\n[GitHub discussions\\n](https://github.com/orgs/spider-rs/discussions)\\n[Discord\\n](https://discord.spider.cloud)\\n[\\n@iammerrick\\nRust based crawler Spider is next level for crawling & scraping sites. So fast. Their cloud offering is also so easy to use. Good stuff. https://github.com/spider-rs/spider\\n](https://twitter.com/iammerrick/status/1787873425446572462)\\n[\\n@WilliamEspegren\\nWeb crawler built in rust, currently the nr1 performance in the world with crazy resource management Aaaaaaand they have a cloud offer, that‚Äôs wayyyy cheaper than any competitor Name a reason for me to use anything else? github.com/spider-rs/spid‚Ä¶\\n](https://twitter.com/WilliamEspegren/status/1789419820821184764)\\n[\\n@gasa\\n@gasathenaper is the best crawling tool i have used. I had a complicated project where i needed to paste url and get the website whole website data. Spider cloud does it in an instant\\n](https://x.com/gasathenaper/status/1810612492596383948)\\n[\\n@Ashpreet Bedi\\n@ashpreetbedi is THE best crawler out there, give it a try\\n](https://x.com/ashpreetbedi/status/1815512219003572315?s=46&t=37F5QP_8oKqOsNpHSo6VVw)\\n[\\n@Troyusrex\\nI found a new tool, Spider-rs, which scrapes significantly faster and handles more scenarios than the basic scraper I built did. Our use of Spider-rs and AWS infrastructure reduced the scraping time from four months to under a week.\\n](https://medium.com/@troyusrex/inside-my-virtual-college-advisor-a-deep-dive-into-rag-ai-and-agent-technology-84731b2928f7#1326)\\n[\\n@Dify.AI\\nüï∑Ô∏è Spider @spider\\\\_rust can be used as a built-in tool in #Dify Workflow or as an LLM-callable tool in Agent. It allows fast and affordable web scraping and crawling when your AI applications need real-time web data for context.\\n](https://x.com/dify_ai/status/1818226971056243089)\\n## FAQ\\nFrequently asked questions about Spider.\\n### What is Spider?\\nSpider is a leading web crawling tool designed for speed and cost-effectiveness, supporting various data formats including LLM-ready markdown.\\n### Why is my website not crawling?\\nYour crawl may fail if it requires JavaScript rendering. Try setting your request to \\'chrome\\' to solve this issue.\\n### Can you crawl all pages?\\nYes, Spider accurately crawls all necessary content without needing a sitemap.\\n### What formats can Spider convert web data into?\\nSpider outputs HTML, raw, text, and various markdown formats. It supports`JSON`,`JSONL`,`CSV`, and`XML`for API responses.\\n### Is Spider suitable for large scraping projects?\\nAbsolutely, Spider is ideal for large-scale data collection and offers a cost-effective dashboard for data management.\\n### How can I try Spider?\\nPurchase credits for our cloud system or test the Open Source Spider engine to explore its capabilities.\\n### Does it respect robots.txt?\\nYes, compliance with robots.txt is default, but you can disable this if necessary.\\n### Unable to get dynamic content?\\nIf you are having trouble getting dynamic pages, try setting the request parameter to \"chrome\" or \"smart.\" You may also need to set `disable\\\\_intercept` to allow third-party or external scripts to run.\\n### Why is my crawl going slow?\\nIf you are experiencing a slow crawl, it is most likely due to the robots.txt file for the website. The robots.txt file may have a crawl delay set, and we respect the delay up to 60 seconds.\\n### Do you offer a Free Trial?\\nYes, you can try out the service before being charged for free at[checkout](https://spider.cloud/credits/new?free-trial=1).\\n## Comprehensive Data Curation for Everyone\\nTrusted by leading tech businesses worldwide to deliver accurate and insightful data solutions.\\n[](https://zapier.com/apps/spider/integrations)\\n### Next generation data for AI, scale to millions\\n[Start now](https://spider.cloud/credits/new)\\n### Company\\n* [About](https://spider.cloud/about)\\n* [Privacy](https://spider.cloud/privacy)\\n* [Terms](https://spider.cloud/eula)\\n* [FAQ](https://spider.cloud/faq)\\n### Resources\\n* [API](https://spider.cloud/docs/api)\\n* [Docs](https://spider.cloud/docs/overview)\\n* [Guides](https://spider.cloud/guides)\\n* [Spider.rs Docs](https://docs.rs/spider/latest/spider/)\\n### Services\\n* [Pricing](https://spider.cloud/credits/new)\\n* [Web Crawling and Scraping](https://spider.cloud/web-crawling-and-scraping)\\n[All systems normal.](https://spidercloud.statuspage.io/)\\n[GitHub](https://github.com/spider-rs/spider)\\n[Discord](https://discord.spider.cloud)\\n[Twitter](https://twitter.com/spider_rust)\\n', 'type': 'Document'}]}\n",
      "--------------------------------------------------\n",
      "Transition type:  finish\n",
      "Transition output:  Spider.cloud is a cutting-edge web crawling service designed for AI applications, offering high-speed and cost-effective data collection. Built with a robust Rust engine, Spider supports seamless integration with AI tools and provides various response formats, including LLM-ready markdown. It features concurrent streaming, caching, smart mode with headless Chrome, and auto proxy rotations. Ideal for large-scale projects, Spider ensures compliance with robots.txt and offers a free trial. Trusted by tech leaders, it enables efficient data curation and transformation, with capabilities to handle extreme workloads and dynamic content rendering.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lists all the task steps that have been executed up to this point in time\n",
    "transitions = client.executions.transitions.list(execution_id=execution.id).items\n",
    "\n",
    "# Transitions are retreived in reverse chronological order\n",
    "for transition in reversed(transitions):\n",
    "    print(\"Transition type: \", transition.type)\n",
    "    print(\"Transition output: \", transition.output)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the same task with a different URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same code to run the same task, but with a different URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = client.executions.create(\n",
    "    task_id=TASK_UUID,\n",
    "    input={\n",
    "        \"url\": \"https://www.harvard.edu/\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvard University's website highlights its commitment to excellence in teaching, research, and leadership development globally\n",
      "It offers diverse academic programs, including undergraduate, graduate, and professional learning\n",
      "The site features information about Harvard's various schools, libraries, museums, and research initiatives\n",
      "It emphasizes Harvard's global impact, historical achievements, and contributions to fields like climate change, medicine, and biodiversity\n",
      "The site also provides resources for campus visits, events, and news updates, showcasing Harvard's vibrant community and its role in advancing knowledge and societal well-being.\n"
     ]
    }
   ],
   "source": [
    "execution = client.executions.get(execution.id)\n",
    "print(\"\\n\".join(execution.output.split(\". \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can get the output of the crawling step by accessing the corresponding transition's output from the transitions list.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': [{'id': None,\n",
       "   'metadata': {'description': 'Harvard University is devoted to excellence in teaching, learning, and research, and to developing leaders who make a difference globally.',\n",
       "    'domain': 'www.harvard.edu',\n",
       "    'extracted_data': None,\n",
       "    'file_size': 19620,\n",
       "    'keywords': ['Amazon rainforest immersion',\n",
       "     'Ants Army ants',\n",
       "     'Arnold Arboretum Horticultural Library',\n",
       "     'Cabot Science Library',\n",
       "     'Dumbarton Oaks Research Library',\n",
       "     'Ernst Mayr Library',\n",
       "     'Fine Arts Library',\n",
       "     'Frances Loeb Library',\n",
       "     'Griffin Graduate School',\n",
       "     'Harvard Amazon Rainforest Immersion program',\n",
       "     'Harvard Art Museums',\n",
       "     'Harvard Business School',\n",
       "     'Harvard Divinity School',\n",
       "     'Harvard Divinity School Library',\n",
       "     'Harvard Film Archive',\n",
       "     'Harvard Forest research project explored naturalist Frank Morton Jones',\n",
       "     'Harvard Graduate School',\n",
       "     'Harvard Kennedy School',\n",
       "     'Harvard Law School',\n",
       "     'Harvard Law School Library',\n",
       "     'Harvard Map Collection',\n",
       "     'Harvard Medical School',\n",
       "     'Harvard Radcliffe Institute',\n",
       "     'Harvard Schools Academics Visit',\n",
       "     'Harvard University Archives',\n",
       "     'Harvard University Herbaria',\n",
       "     'Harvard scientist Gary Ruvkun awarded medicine prize',\n",
       "     'Historical Scientific Instruments',\n",
       "     'Howler monkeys Monkeys don',\n",
       "     'Loeb Music Library',\n",
       "     'Meet Professor Gary Ruvkun',\n",
       "     'Moose Harvard Forest',\n",
       "     'Recent topics include',\n",
       "     'Report Copyright Infringement',\n",
       "     'Report Security Issue',\n",
       "     'Trending News Stories News',\n",
       "     'Warren Anatomical Museum',\n",
       "     'Woodberry Poetry Room',\n",
       "     'Worms Invasive worms',\n",
       "     'altering soil composition',\n",
       "     'boost mental health',\n",
       "     'climate change mitigation',\n",
       "     'collective foraging behavior',\n",
       "     'die-hard Harvard buffs',\n",
       "     'eastern North America',\n",
       "     'eliminating ground cover',\n",
       "     'endangered Chinese tree',\n",
       "     'forest fires impact',\n",
       "     'forests Climate change',\n",
       "     'growing global population continue',\n",
       "     'long-term ecological research site located',\n",
       "     'mycorrhizae plays important roles',\n",
       "     'offset carbon emissions',\n",
       "     'people experience long COVID symptoms',\n",
       "     'pitcher plant research',\n",
       "     'rainforests promote biodiversity',\n",
       "     'temperate woody plants',\n",
       "     'woods Research shows'],\n",
       "    'pathname': '/',\n",
       "    'resource_type': '.md',\n",
       "    'title': 'Harvard University',\n",
       "    'url': '8475428e-4e0c-44de-967f-c14fb73cf490/www.harvard.edu/www_edu/12638123428881205758.md',\n",
       "    'user_id': '8475428e-4e0c-44de-967f-c14fb73cf490'},\n",
       "   'page_content': \"Harvard University\\n[Skip to main content](#main-content)\\n[Harvard University](https://www.harvard.edu/)\\nSearch\\n**SearchQuick Links**\\n1. [A to Z index](https://www.harvard.edu/a-to-z/)\\nMenu\\n1. Academics\\n\\nAcademics\\n**[Academics](https://www.harvard.edu/academics/)**Learning at Harvard can happen for every type of learner, at any phase of life.\\n\\n1. Degree programs\\n\\nAcademics\\n**Degree programs**Browse all of our undergraduate concentrations and graduate degrees.\\n\\n1. [**Undergraduate Degrees**](https://www.harvard.edu//programs/?degree_levels=undergraduate)\\n 2. [**Graduate Degrees**](https://www.harvard.edu//programs/?degree_levels=graduate)\\n 3. [**Other**](https://www.harvard.edu/academics/professional-and-lifelong-learning/)\\n\\n2. [Professional and Lifelong Learning](https://www.harvard.edu/academics/professional-and-lifelong-learning/)\\n 3. [Harvard Online](https://www.harvardonline.harvard.edu/)\\n 4. Harvard Schools\\n\\nAcademics\\nVisit each School for information on admissions and financial aid.[Explore more](/schools/)\\n\\n1. [**Harvard College**](https://college.harvard.edu/)\\n 2. [**Harvard Business School**](http://www.hbs.edu)\\n 3. [**Harvard Division of Continuing Education**](https://www.dce.harvard.edu/)\\n 4. [**Harvard Divinity School**](https://hds.harvard.edu/)\\n 5. [**Harvard Faculty of Arts and Sciences**](https://www.fas.harvard.edu/)\\n 6. [**Harvard Kenneth C. Griffin Graduate School of Arts and Sciences**](https://gsas.harvard.edu/)\\n 7. [**Harvard Graduate School of Design**](https://www.gsd.harvard.edu/)\\n 8. [**Harvard Graduate School of Education**](https://gse.harvard.edu/)\\n 9. [**Harvard John A. Paulson School of Engineering and Applied Sciences**](https://www.seas.harvard.edu/)\\n 10. [**Harvard Kennedy School**](https://www.hks.harvard.edu/)\\n 11. [**Harvard Law School**](https://hls.harvard.edu/)\\n 12. [**Harvard Medical School**](https://hms.harvard.edu/)\\n 13. [**Harvard Radcliffe Institute**](https://www.radcliffe.harvard.edu/)\\n 14. [**Harvard School of Dental Medicine**](https://hsdm.harvard.edu/)\\n 15. [**Harvard T.H. Chan School of Public Health**](https://www.hsph.harvard.edu/)\\n\\n2. Campus\\n\\nCampus\\n**[Harvard's Campus](https://www.harvard.edu/campus/)**Get tickets to our next game, hours and locations for our libraries and museums, and information about your next career move.\\n\\n1. Libraries\\n\\nCampus\\n[Explore our libraries](https://www.harvard.edu/campus/libraries/)\\n\\n1. [**Arnold Arboretum Horticultural Library**](https://arboretum.harvard.edu/research/library/)\\n 2. [**Baker Library and Special Collections**](https://www.library.hbs.edu/)\\n 3. [**Biblioteca Berenson**](http://itatti.harvard.edu/berenson-library)\\n 4. [**Botany Libraries**](https://huh.harvard.edu/libraries)\\n 5. [**Cabot Science Library**](https://library.harvard.edu/libraries/cabot)\\n 6. [**Countway Library**](https://countway.harvard.edu/)\\n 7. [**Dumbarton Oaks Research Library**](https://www.doaks.org/research/library-archives)\\n 8. [**Ernst Mayr Library**](https://library.mcz.harvard.edu/)\\n 9. [**Fine Arts Library**](https://library.harvard.edu/libraries/fine-arts)\\n 10. [**Frances Loeb Library**](https://www.gsd.harvard.edu/frances-loeb-library/)\\n 11. [**Fung Library**](https://library.harvard.edu/libraries/fung)\\n 12. [**Gutman Library**](https://gse.harvard.edu/community/library)\\n 13. [**Harvard Divinity School Library**](https://library.hds.harvard.edu/)\\n 14. [**Harvard Film Archive**](https://harvardfilmarchive.org/)\\n 15. [**Harvard Law School Library**](https://hls.harvard.edu/library/)\\n 16. [**Harvard Map Collection**](https://library.harvard.edu/libraries/harvard-map-collection)\\n 17. [**Harvard University Archives**](https://library.harvard.edu/libraries/harvard-university-archives)\\n 18. [**Harvard-Yenching Library**](https://library.harvard.edu/libraries/yenching)\\n 19. [**HKS Library and Knowledge Services**](https://www.hks.harvard.edu/research-insights/library-knowledge-services)\\n 20. [**Houghton Library**](https://library.harvard.edu/libraries/houghton)\\n 21. [**Lamont Library**](https://library.harvard.edu/libraries/lamont)\\n 22. [**Loeb Music Library**](https://library.harvard.edu/libraries/loeb-music)\\n 23. [**Robbins Library of Philosophy**](https://library.harvard.edu/libraries/robbins-philosophy)\\n 24. [**Schlesinger Library on the History of Women in America**](https://www.radcliffe.harvard.edu/schlesinger-library)\\n 25. [**Tozzer Library**](https://library.harvard.edu/libraries/tozzer)\\n 26. [**Widener Library**](https://library.harvard.edu/libraries/widener)\\n 27. [**Woodberry Poetry Room**](https://library.harvard.edu/libraries/poetryroom)\\n\\n2. Museums\\n\\nCampus\\n[Explore our museums](https://www.harvard.edu/campus/museums/)\\n\\n1. [**The Arnold Arboretum**](http://www.arboretum.harvard.edu/)\\n 2. [**Carpenter Center for the Visual Arts**](http://ccva.fas.harvard.edu/)\\n 3. [**Collection of Historical Scientific Instruments**](http://chsi.harvard.edu/)\\n 4. [**Graduate School of Design Exhibitions**](http://www.gsd.harvard.edu/exhibitions/)\\n 5. [**Harvard Art Museums**](http://www.harvardartmuseums.org/)\\n 6. [**Harvard Forest**](https://harvardforest.fas.harvard.edu/)\\n 7. [**Harvard Museum of Natural History**](http://www.hmnh.harvard.edu/)\\n 8. [**The Harvard Museum of the Ancient Near East**](https://hmane.harvard.edu/)\\n 9. [**Harvard Museums of Science and Culture**](http://hmsc.harvard.edu/)\\n 10. [**Harvard University Herbaria**](http://www.huh.harvard.edu/)\\n 11. [**Mineralogical and Geological Museum**](http://mgmh.fas.harvard.edu/)\\n 12. [**Museum of Comparative Zoology**](http://www.mcz.harvard.edu/)\\n 13. [**The Peabody Museum of Archaeology and Ethnology**](http://www.peabody.harvard.edu/)\\n 14. [**Warren Anatomical Museum**](https://countway.harvard.edu/center-history-medicine/collections-research-access/warren-anatomical-museum-collection)\\n\\n3. [Athletics](https://www.harvard.edu/campus/athletics/)\\n 4. [Work at Harvard](https://www.harvard.edu/campus/work-at-harvard/)\\n 5. [Events](https://news.harvard.edu/gazette/harvard-events/)\\n 6. [Commencement](http://commencement.harvard.edu/)\\n\\n3. In Focus\\n\\nIn Focus\\n**Explore and understand the world with Harvard**In Focus is a curated examination of Harvard's research, scholarly work, and community. Recent topics include:\\n\\n1. Forests\\n\\nIn Focus\\n**Forests**From sprawling jungles to city parks, forests are complex ecosystems that support the livelihoods of flora, fauna, humans, and the planet.[Take a hike](https://www.harvard.edu/in-focus/forests/)\\n\\n1. **What's inside?**\\n 1. [\\n **Urban forests can help cool cities**](https://www.gsd.harvard.edu/2023/10/the-forest-for-the-trees-and-the-birds-and-the-people-and-the-planet/)\\n 2. [\\n **Forests can help offset carbon emissions**](https://news.harvard.edu/gazette/story/2022/11/new-report-shows-forests-have-big-role-to-play-in-climate-change-fight/)\\n\\n2. Harvard in the World\\n\\nIn Focus\\n**Harvard in the World**Harvard faculty, students, and alumni compose a global network that is exploring\\xa0health, law, government, education, business, and more around the world.[Explore the globe](https://www.harvard.edu/in-focus/harvard-in-the-world/)\\n\\n1. **What's inside**\\n 1. [\\n **Journey to the Amazon**](https://news.harvard.edu/gazette/story/2024/10/journey-to-a-key-front-in-climate-change-fight/)\\n 2. [\\n **Learn about Worldwide Week at Harvard**](https://worldwide.harvard.edu/worldwide-week-harvard-2024)\\n\\n3. Nobels at Harvard\\n\\nIn Focus\\n**Nobels at Harvard**Explore Harvard's history with the Nobel Prize and learn about winners past and present.[View the feature](https://www.harvard.edu/in-focus/nobels-at-harvard/)\\n\\n1. **What's inside**\\n 1. [\\n **Meet Professor Gary Ruvkun, a 2024 winner**](https://news.harvard.edu/gazette/story/2024/10/harvard-scientist-awarded-nobel/)\\n 2. [\\n **Meet Harvard's Nobel Laureates**](https://www.harvard.edu/about/history/nobel-laureates/)\\n\\n4. [\\n Explore the In Focus archives](https://www.harvard.edu/in-focus/)\\n\\n4. Visit\\n\\nVisit\\n**[Visit Harvard](https://www.harvard.edu/visit/)**Ideas and assistance for your trip to our campus.\\n\\n1. [Tours](https://www.harvard.edu/visit/tours/)\\n 2. [Maps and directions](https://www.harvard.edu/visit/maps-directions/)\\n 3. [Tour Providers](https://www.harvard.edu/visit/tour-providers/)\\n\\n5. About\\n\\nAbout\\n**[About Harvard](https://www.harvard.edu/about/)**Learn how Harvard is structured, explore our long history, and discover our extended community.\\n\\n1. History of Harvard\\n\\nAbout\\n**History of Harvard**Harvard is perhaps best-known because of its enduring history of innovation in education. But even die-hard Harvard buffs are not likely to know all of these Harvard firsts and historical snippets.[Learn more](https://www.harvard.edu/about/history/)\\n\\n1. [**History timeline**](https://www.harvard.edu/about/history/timeline/)\\n 2. [**Nobel Laureates**](https://www.harvard.edu/about/history/nobel-laureates/)\\n 3. [**Honorary Degrees**](https://www.harvard.edu/about/history/honorary-degrees/)\\n 4. [**Harvard shields**](https://www.harvard.edu/about/history/shields/)\\n\\n2. Leadership and governance\\n\\nAbout\\n[Learn about our Leadership](https://www.harvard.edu/about/leadership-and-governance/)\\n\\n1. [**President**](https://www.harvard.edu//president/)\\n 2. [**Officers and Deans**](https://www.harvard.edu/about/leadership-and-governance/officers-and-deans/)\\n 3. [**Harvard Corporation**](https://www.harvard.edu/about/leadership-and-governance/harvard-corporation/)\\n 4. [**Board of Overseers**](https://www.harvard.edu/about/leadership-and-governance/board-of-overseers/)\\n\\n3. [University Professorships](https://www.harvard.edu/about/university-professorships/)\\n 4. [Diversity and Inclusion](https://www.harvard.edu/about/diversity-and-inclusion/)\\n 5. [Endowment](https://www.harvard.edu/about/endowment/)\\n 6. [Harvard in the Community](https://www.harvard.edu/about/harvard-in-the-community/)\\n 7. [Harvard in the World](https://www.harvard.edu/about/harvard-in-the-world/)\\n\\n6. News\\n\\nNews\\n**[The Harvard Gazette](https://news.harvard.edu/gazette/)**Official news from Harvard University about science, medicine, art, campus life, University issues, and broader national and global concerns.\\n\\n1. Trending News Stories\\n\\nNews\\n[Read more news](http://news.harvard.edu)\\n\\n1. [**Unearthed papyrus contains lost scenes from Euripides‚Äô plays**Alums help identify, decipher ‚Äòone of the most significant new finds in Greek literature in this century‚Äô\\n ](https://news.harvard.edu/gazette/story/2024/10/unearthed-papyrus-contains-lost-scenes-from-euripides-plays/)\\n2. [**What‚Äôs next after a Nobel? It‚Äôs a surprise.**Harvard scientist Gary Ruvkun awarded medicine prize for microRNA insights. ‚ÄòMy ignorance is bliss,‚Äô he says.\\n ](https://news.harvard.edu/gazette/story/2024/10/harvard-scientist-awarded-nobel/)\\n3. [**Getting to the bottom of long COVID**A reservoir of virus in the body may explain why some people experience long COVID symptoms\\n ](https://news.harvard.edu/gazette/story/2024/10/getting-to-the-bottom-of-long-covid/)\\n\\n2. [Sign up for the Daily Gazette](https://www.pages01.net/harvard/gazette?email=)\\n\\n**NavigationQuick Links**\\n1. [A to Z index](https://www.harvard.edu/a-to-z/)\\n2. [Find a person](https://connections.harvard.edu/)\\n3. [Events](https://news.harvard.edu/gazette/harvard-events/)\\n4. [Media Relations](/media-relations)\\n5. [Alumni](https://alumni.harvard.edu/)\\n6. [Give Now](https://alumni.harvard.edu/giving/givenow)\\n7. [Emergency](https://www.harvard.edu/emergency/)\\n[Harvard University](https://www.harvard.edu/)\\nClose\\n# Harvard University\\n## Forests\\nFrom sprawling jungles to city parks, forests are complex ecosystems that support the livelihoods of flora, fauna, humans, and the planet.\\n## Our forests\\nHarvard maintains and stewards two forests where we house a living collection of plants and expand our forest knowledge through research.\\n### Harvard Forest\\nA 4000-acre laboratory, classroom, and long-term ecological research site located in central Massachusetts.\\nLearn more about Harvard Forest\\n[Learn more about Harvard Forest](https://harvardforest.fas.harvard.edu/)\\n### Arnold Arboretum\\nA 281-acre preserve of temperate woody plants from eastern North America and eastern Asia, located in the Boston neighborhood of Jamaica Plain.\\nLearn more about the Arboretum\\n[Learn more about the Arboretum](https://arboretum.harvard.edu/)\\n## How forests help us\\nForest play a major role in[the planet‚Äôs overall wellbeing](https://repository.gheli.harvard.edu/repository/12580/), from sequestering carbon and creating oxygen to fostering a diversity of life.\\n### [Forests help offset carbon emissions](https://news.harvard.edu/gazette/story/2022/11/new-report-shows-forests-have-big-role-to-play-in-climate-change-fight/)\\n[Learn more about forests‚Äô role in climate change mitigation](https://news.harvard.edu/gazette/story/2020/08/new-englands-trees-capturing-more-carbon-says-25-year-study/)\\n### [Rainforests are an engine of diverse life](https://news.harvard.edu/gazette/story/2018/07/study-says-rainforests-gave-birth-to-worlds-most-varied-tropical-region/)\\n[Learn more about how rainforests promote biodiversity](https://arboretum.harvard.edu/stories/resolving-the-enigma-of-rainforest-biodiversity/)\\n### [Urban forests can help cool cities](https://www.hsph.harvard.edu/news/features/linear-urban-forest-project-aims-to-mitigate-heat-improve-health-in-cities/)\\n[Learn more about the benefits of urban forests](https://www.gsd.harvard.edu/2023/10/the-forest-for-the-trees-and-the-birds-and-the-people-and-the-planet/)\\n## Forest flora\\n[Explore more plant life](https://arboretum.harvard.edu/plants/)\\n### Paperbark Maple\\nThe Arboretum has been active in the conservation of this endangered Chinese tree for more than a century.\\nLearn more about the tree\\n[Learn more about the tree](https://arboretum.harvard.edu/plant-bios/paperbark-maple/)\\n### Pitcher plants\\nA Harvard Forest research project explored naturalist Frank Morton Jones‚Äô pitcher plant research.\\nLearn more about carnivorous plants\\n[Learn more about carnivorous plants](https://harvardforest.fas.harvard.edu/ellison/current-research/Frank-Morton-Jones)\\n### Sapria himalayana\\nThese unusual plants have no roots, stems, or leaves of their own, living only as a collection of cells until they produce some of the largest flowers in the world.\\nLearn more about this strange, stinky flower\\n[Learn more about this strange, stinky flower](https://news.harvard.edu/gazette/story/2021/01/harvard-researchers-sequence-sapria-genome/)\\nInside Harvard‚Äôs Amazon rainforest immersion\\n[Click to Play Video](https://youtu.be/yTOEaON95DA)\\n## Forests around the world\\nHarvard researchers are exploring and supporting forests all over the world, including plant expeditions in[Japan](https://arboretum.harvard.edu/stories/science-and-spirit-in-the-forests-of-central-honshu/)and the[Pacific Northwest](https://arboretum.harvard.edu/expeditions/oregon-and-washington-expedition-owe/), Amazon conservation in[Brazil](https://hir.harvard.edu/the-waiapi-tribe-the-protectors-of-the-amazon-rainforest/)and[Peru](https://revista.drclas.harvard.edu/saving-latin-america-forests/), and a deep dive into the forests right in our[New England](https://hmnh.harvard.edu/new-england-forests)backyard.\\n[Learn about the Harvard Amazon Rainforest Immersion program](https://news.harvard.edu/gazette/story/2024/10/journey-to-a-key-front-in-climate-change-fight/)\\n## How we can help forests\\nClimate change and a growing global population continue to be detrimental to the world‚Äôs forests, but researchers are working to understand and mitigate those threats.\\n### Invasion\\n[How global shipping may bring pests that threaten our forests](https://harvardforest.fas.harvard.edu/news/old-growth-forests-elders-under-threat)\\n### Preservation\\n[How deforestation can affect the surviving forests](https://environment.harvard.edu/news/deforestation-damages-even-rainforests-survive-it)\\n### Conflagration\\n[How forest fires impact the world](https://news.harvard.edu/gazette/story/2023/06/in-the-thick-of-canadian-wildfires/)\\n## Forest fauna\\n[Explore more wildlife](https://arboretum.harvard.edu/visit/wildlife-at-the-arboretum/)\\n### Mink\\nA member of the weasel family, minks have been seen at the Arboretum for several years, typically near wetlands.\\nLearn more about the Arboretum‚Äôs newest residents\\n[Learn more about the Arboretum‚Äôs newest residents](https://arboretum.harvard.edu/stories/fishers-weasels-are-latest-residents-of-bostons-arboretum/)\\n### Howler monkeys\\nMonkeys don‚Äôt just consume fruits, but also make forest by dispersing the seeds of trees they consume.\\nLearn more about monkeys‚Äô relationship to the forests they inhabit\\n[Learn more about monkeys‚Äô relationship to the forests they inhabit](https://revista.drclas.harvard.edu/how-monkeys-create-tropical-rainforests/)\\n### Moose\\nHarvard Forest‚Äôs wildlife cameras have spotted moose and deer using their trees.\\nExplore more animals from Harvard Forest\\n[Explore more animals from Harvard Forest](https://harvardforest.fas.harvard.edu/browsing-wildlife-photos)\\n## []()\\n### Walking in the woods\\nResearch shows that hiking and ‚Äúforest baths‚Äù have physical and mental benefits.\\n[Learn how the woods can help boost mental health](https://magazine.hms.harvard.edu/articles/walk-woods-may-boost-mental-health)\\n[Learn more about ‚Äúforest bathing‚Äù](https://arboretum.harvard.edu/stories/walk-into-a-forest-breathe-deeply-repeat-as-needed/)\\n## Underground dwellers\\n### Mycorrhizae\\nA connection produced between a plant and fungi that live in the plant‚Äôs roots, mycorrhizae plays important roles in plant nutrition and soil biology and chemistry.\\nLearn more about this symbiotic relationship\\n[Learn more about this symbiotic relationship](https://arboretum.harvard.edu/stories/food-poison-and-espionage-mycorrhizal-networks-in-action/)\\n### Worms\\nInvasive worms are eliminating ground cover and altering soil composition, threatening some plant communities in New England.\\nLearn more about worms\\n[Learn more about worms](https://arboretum.harvard.edu/stories/native-plants-and-the-crazy-snake-worm/)\\n### Ants\\nArmy ants‚Äô mass raids are considered the pinnacle of collective foraging behavior in the animal kingdom, but scientists are only just learning how they evolved to create them.\\nLearn how ant raids have evolved\\n[Learn how ant raids have evolved](https://oeb.harvard.edu/news/how-army-ants-iconic-mass-raids-evolved)\\nYou may also like\\n## Related In Focus topics\\n* [Arboretum Anniversary](https://www.harvard.edu/in-focus/arboretum-anniversary/)\\n* [Animal Magnetism](https://www.harvard.edu/in-focus/animal-magnetism/)\\n* [Earth Science](https://www.harvard.edu/in-focus/earth-science/)\\n## Security & Brand\\n1. [Report Copyright Infringement](https://www.harvard.edu/copyright-issue/)\\n2. [Report Security Issue](https://www.harvard.edu/security-issue/)\\n3. [Trademark Notice](https://trademark.harvard.edu/pages/trademark-notice)\\n## Website\\n1. [Accessibility](https://accessibility.harvard.edu/)\\n2. [Digital Accessibility](https://accessibility.huit.harvard.edu/digital-accessibility-policy)\\n3. [Privacy statement](https://www.harvard.edu/privacy-statement/)\\n## Get In Touch\\n1. [Contact Harvard](/contact-harvard)\\n2. [Maps & Directions](/maps-directions)\\n3. [Jobs](http://hr.harvard.edu/jobs)\\nCopyright ¬© 2024 The President and Fellows of Harvard College\\n[](https://www.harvard.edu/)\\n* [Instagram](https://www.instagram.com/harvard/)\\n* [TikTok](https://www.tiktok.com/@harvard)\\n* [LinkedIn](https://www.linkedin.com/school/harvard-university)\\n* [Facebook](https://www.facebook.com/Harvard/)\\n* [YouTube](https://www.youtube.com/harvard)\\n\",\n",
       "   'type': 'Document'}]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions = client.executions.transitions.list(execution_id=execution.id).items\n",
    "\n",
    "transitions[1].output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
