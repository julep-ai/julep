# generated by datamodel-codegen:
#   filename:  openapi-1.0.0.yaml

from __future__ import annotations

from typing import Annotated, Any, Literal
from uuid import UUID

from pydantic import AwareDatetime, BaseModel, ConfigDict, Field, StrictBool


class BaseDocSearch(BaseModel):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    limit: Annotated[int, Field(ge=1, le=50)] = 10
    """
    The limit of documents to return
    """
    lang: str = "en-US"
    """
    The language to be used for text-only search. Support for other languages coming soon.
    """
    metadata_filter: dict[str, Any] = {}
    """
    Metadata filter to apply to the search
    """
    num_search_messages: Annotated[int, Field(ge=1, le=50)] = 4
    """
    The number of search messages to use for the search.
    """
    max_query_length: Annotated[int, Field(ge=1, le=1000)] = 1000
    """
    The maximum query length to use for the search.
    """


class BaseDocSearchUpdate(BaseDocSearch):
    pass


class CreateSessionRequest(BaseModel):
    """
    Payload for creating a session
    """

    model_config = ConfigDict(
        populate_by_name=True,
    )
    user: UUID | None = None
    """
    User ID of user associated with this session
    """
    users: list[UUID] | None = None
    agent: UUID | None = None
    """
    Agent ID of agent associated with this session
    """
    agents: list[UUID] | None = None
    situation: str | None = None
    """
    Session situation
    """
    system_template: str | None = None
    """
    A specific system prompt template that sets the background for this session
    """
    render_templates: StrictBool = True
    """
    Render system and assistant message content as jinja templates
    """
    token_budget: int | None = None
    """
    Threshold value for the adaptive context functionality
    """
    context_overflow: Literal["truncate", "adaptive"] | None = None
    """
    Action to start on context window overflow
    """
    auto_run_tools: StrictBool = False
    """
    Whether to auto-run the tool and send the tool results to the model when available.
    (default: false for sessions, true for tasks)

    If a tool call is made, the tool's output will be sent back to the model as the model's input.
    If a tool call is not made, the model's output will be returned as is.
    """
    forward_tool_calls: StrictBool = False
    """
    Whether to forward tool calls to the model
    """
    recall_options: VectorDocSearch | TextOnlyDocSearch | HybridDocSearch | None = None
    """
    Recall options for the session
    """
    metadata: dict[str, Any] | None = None


class HybridDocSearch(BaseDocSearch):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    mode: str = "hybrid"
    """
    The mode to use for the search.
    """
    confidence: Annotated[float, Field(ge=-1.0, le=1.0)] = 0
    """
    The confidence cutoff level
    """
    alpha: Annotated[float, Field(ge=0.0, le=1.0)] = 0.75
    """
    The weight to apply to BM25 vs Vector search results. 0 => pure BM25; 1 => pure vector;
    """
    mmr_strength: Annotated[float, Field(ge=0.0, lt=1.0)] = 0.5
    """
    Text to use in the search. In `hybrid` search mode, either `text` or both `text` and `vector` fields are required.Vector to use in the search. Must be the same dimensions as the embedding model or else an error will be thrown.MMR Strength (mmr_strength = 1 - mmr_lambda)
    """


class HybridDocSearchUpdate(BaseDocSearchUpdate):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    mode: str = "hybrid"
    """
    The mode to use for the search.
    """
    confidence: Annotated[float, Field(ge=-1.0, le=1.0)] = 0
    """
    The confidence cutoff level
    """
    alpha: Annotated[float, Field(ge=0.0, le=1.0)] = 0.75
    """
    The weight to apply to BM25 vs Vector search results. 0 => pure BM25; 1 => pure vector;
    """
    mmr_strength: Annotated[float, Field(ge=0.0, lt=1.0)] = 0.5
    """
    Text to use in the search. In `hybrid` search mode, either `text` or both `text` and `vector` fields are required.Vector to use in the search. Must be the same dimensions as the embedding model or else an error will be thrown.MMR Strength (mmr_strength = 1 - mmr_lambda)
    """


class PatchSessionRequest(BaseModel):
    """
    Payload for patching a session
    """

    model_config = ConfigDict(
        populate_by_name=True,
    )
    situation: str | None = None
    """
    Session situation
    """
    system_template: str | None = None
    """
    A specific system prompt template that sets the background for this session
    """
    render_templates: StrictBool = True
    """
    Render system and assistant message content as jinja templates
    """
    token_budget: int | None = None
    """
    Threshold value for the adaptive context functionality
    """
    context_overflow: Literal["truncate", "adaptive"] | None = None
    """
    Action to start on context window overflow
    """
    auto_run_tools: StrictBool = False
    """
    Whether to auto-run the tool and send the tool results to the model when available.
    (default: false for sessions, true for tasks)

    If a tool call is made, the tool's output will be sent back to the model as the model's input.
    If a tool call is not made, the model's output will be returned as is.
    """
    forward_tool_calls: StrictBool = False
    """
    Whether to forward tool calls to the model
    """
    recall_options: (
        VectorDocSearchUpdate | TextOnlyDocSearchUpdate | HybridDocSearchUpdate | None
    ) = None
    """
    Recall options for the session
    """
    metadata: dict[str, Any] | None = None


class Session(BaseModel):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    situation: str | None = None
    """
    Session situation
    """
    system_template: str | None = None
    """
    A specific system prompt template that sets the background for this session
    """
    summary: Annotated[str | None, Field(json_schema_extra={"readOnly": True})] = None
    """
    Summary (null at the beginning) - generated automatically after every interaction
    """
    render_templates: StrictBool = True
    """
    Render system and assistant message content as jinja templates
    """
    token_budget: int | None = None
    """
    Threshold value for the adaptive context functionality
    """
    context_overflow: Literal["truncate", "adaptive"] | None = None
    """
    Action to start on context window overflow
    """
    auto_run_tools: StrictBool = False
    """
    Whether to auto-run the tool and send the tool results to the model when available.
    (default: false for sessions, true for tasks)

    If a tool call is made, the tool's output will be sent back to the model as the model's input.
    If a tool call is not made, the model's output will be returned as is.
    """
    forward_tool_calls: StrictBool = False
    """
    Whether to forward tool calls to the model
    """
    recall_options: VectorDocSearch | TextOnlyDocSearch | HybridDocSearch | None = None
    """
    Recall options for the session
    """
    id: Annotated[UUID, Field(json_schema_extra={"readOnly": True})]
    metadata: dict[str, Any] | None = None
    created_at: Annotated[AwareDatetime, Field(json_schema_extra={"readOnly": True})]
    """
    When this resource was created as UTC date-time
    """
    updated_at: Annotated[AwareDatetime, Field(json_schema_extra={"readOnly": True})]
    """
    When this resource was updated as UTC date-time
    """
    kind: str | None = None
    """
    Discriminator property for Session.
    """


class SingleAgentMultiUserSession(Session):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    agent: UUID
    users: Annotated[list[UUID], Field(min_length=2)]


class SingleAgentNoUserSession(Session):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    agent: UUID


class SingleAgentSingleUserSession(Session):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    agent: UUID
    user: UUID


class TextOnlyDocSearch(BaseDocSearch):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    mode: str = "text"
    """
    The mode to use for the search.
    """


class TextOnlyDocSearchUpdate(BaseDocSearchUpdate):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    mode: str = "text"
    """
    The mode to use for the search.
    """


class UpdateSessionRequest(BaseModel):
    """
    Payload for updating a session
    """

    model_config = ConfigDict(
        populate_by_name=True,
    )
    situation: str | None = None
    """
    Session situation
    """
    system_template: str | None = None
    """
    A specific system prompt template that sets the background for this session
    """
    render_templates: StrictBool = True
    """
    Render system and assistant message content as jinja templates
    """
    token_budget: int | None = None
    """
    Threshold value for the adaptive context functionality
    """
    context_overflow: Literal["truncate", "adaptive"] | None = None
    """
    Action to start on context window overflow
    """
    auto_run_tools: StrictBool = False
    """
    Whether to auto-run the tool and send the tool results to the model when available.
    (default: false for sessions, true for tasks)

    If a tool call is made, the tool's output will be sent back to the model as the model's input.
    If a tool call is not made, the model's output will be returned as is.
    """
    forward_tool_calls: StrictBool = False
    """
    Whether to forward tool calls to the model
    """
    recall_options: VectorDocSearch | TextOnlyDocSearch | HybridDocSearch | None = None
    """
    Recall options for the session
    """
    metadata: dict[str, Any] | None = None


class VectorDocSearch(BaseDocSearch):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    mode: str = "vector"
    """
    The mode to use for the search.
    """
    confidence: Annotated[float, Field(ge=-1.0, le=1.0)] = 0
    """
    The confidence cutoff level
    """
    mmr_strength: Annotated[float, Field(ge=0.0, lt=1.0)] = 0.5
    """
    Vector to use in the search. Must be the same dimensions as the embedding model or else an error will be thrown.MMR Strength (mmr_strength = 1 - mmr_lambda)
    """


class VectorDocSearchUpdate(BaseDocSearchUpdate):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    mode: str = "vector"
    """
    The mode to use for the search.
    """
    confidence: Annotated[float, Field(ge=-1.0, le=1.0)] = 0
    """
    The confidence cutoff level
    """
    mmr_strength: Annotated[float, Field(ge=0.0, lt=1.0)] = 0.5
    """
    Vector to use in the search. Must be the same dimensions as the embedding model or else an error will be thrown.MMR Strength (mmr_strength = 1 - mmr_lambda)
    """


class CreateOrUpdateSessionRequest(CreateSessionRequest):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    id: UUID
    user: UUID | None = None
    """
    User ID of user associated with this session
    """
    users: list[UUID] | None = None
    agent: UUID | None = None
    """
    Agent ID of agent associated with this session
    """
    agents: list[UUID] | None = None
    situation: str | None = None
    """
    Session situation
    """
    system_template: str | None = None
    """
    A specific system prompt template that sets the background for this session
    """
    render_templates: StrictBool = True
    """
    Render system and assistant message content as jinja templates
    """
    token_budget: int | None = None
    """
    Threshold value for the adaptive context functionality
    """
    context_overflow: Literal["truncate", "adaptive"] | None = None
    """
    Action to start on context window overflow
    """
    auto_run_tools: StrictBool = False
    """
    Whether to auto-run the tool and send the tool results to the model when available.
    (default: false for sessions, true for tasks)

    If a tool call is made, the tool's output will be sent back to the model as the model's input.
    If a tool call is not made, the model's output will be returned as is.
    """
    forward_tool_calls: StrictBool = False
    """
    Whether to forward tool calls to the model
    """
    recall_options: VectorDocSearch | TextOnlyDocSearch | HybridDocSearch | None = None
    """
    Recall options for the session
    """
    metadata: dict[str, Any] | None = None


class MultiAgentMultiUserSession(Session):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    agents: Annotated[list[UUID], Field(min_length=2)]
    users: Annotated[list[UUID], Field(min_length=2)]


class MultiAgentNoUserSession(Session):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    agents: Annotated[list[UUID], Field(min_length=2)]


class MultiAgentSingleUserSession(Session):
    model_config = ConfigDict(
        populate_by_name=True,
    )
    agents: Annotated[list[UUID], Field(min_length=2)]
    user: UUID
